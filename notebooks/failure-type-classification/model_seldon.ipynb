{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4392ea3b-9c11-4b33-854a-4d9232279e1a",
   "metadata": {},
   "source": [
    "# Seldon deployment of failure classification\n",
    "In this notebook, we deploy a service for classifying flakes. We take the experiments in the [failure type classifier notebook](failure_type_classifier.ipynb) and train a sklearn pipeline with all the components, store the pipeline on S3, and deploy it using Seldon. Finally, we test the service for inference on an example request. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7231359-8ec1-484a-a36a-a60c5be94932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import gzip\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import warnings\n",
    "from scipy.signal import convolve2d\n",
    "import joblib\n",
    "import boto3\n",
    "import requests\n",
    "\n",
    "from ipynb.fs.defs.failure_type_functions import (\n",
    "    CephCommunication,\n",
    "    FailureClassifier\n",
    ")\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a8940d-288b-4f79-9d9d-9d08bf73d97b",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c09ef83-d7f5-4092-8cae-324d8476f7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Specify variables\n",
    "\n",
    "METRIC_NAME = \"failure_type\"\n",
    "\n",
    "# Specify the path for input grid data\n",
    "INPUT_DATA_PATH = \"../../data/raw/testgrid_810.json.gz\"\n",
    "\n",
    "# Specify the path for output metric data\n",
    "OUTPUT_DATA_PATH = f\"../../data/processed/metrics/{METRIC_NAME}\"\n",
    "\n",
    "## CEPH Bucket variables\n",
    "## Create a .env file on your local with the correct configs\n",
    "\n",
    "s3_endpoint_url = os.getenv(\"S3_ENDPOINT\")\n",
    "s3_access_key = os.getenv(\"S3_ACCESS_KEY\")\n",
    "s3_secret_key = os.getenv(\"S3_SECRET_KEY\")\n",
    "s3_bucket = os.getenv(\"S3_BUCKET\")\n",
    "s3_path = os.getenv(\"S3_PROJECT_KEY\", \"metrics\")\n",
    "s3_input_data_path = \"raw_data\"\n",
    "s3_output_data_path = \"failure_type\"\n",
    "\n",
    "# Specify whether or not we are running this as a notebook or part of an automation pipeline.\n",
    "AUTOMATION = os.getenv(\"IN_AUTOMATION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b3e6b0b-c976-4183-b94b-3b84f242bd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import data\n",
    "timestamp = datetime.datetime.today()\n",
    "filename = f\"testgrid_{timestamp.day}{timestamp.month}.json\"\n",
    "# timestamp = datetime.datetime(2021, 4, 14)\n",
    "\n",
    "if AUTOMATION:\n",
    "    filename = f\"testgrid_{timestamp.day}{timestamp.month}.json\"\n",
    "    cc = CephCommunication(s3_endpoint_url, s3_access_key, s3_secret_key, s3_bucket)\n",
    "    s3_object = cc.s3_resource.Object(s3_bucket, f\"{s3_input_data_path}/{filename}\")\n",
    "    file_content = s3_object.get()[\"Body\"].read().decode(\"utf-8\")\n",
    "    testgrid_data = json.loads(file_content)\n",
    "\n",
    "else:\n",
    "    with gzip.open(INPUT_DATA_PATH, \"rb\") as read_file:\n",
    "        testgrid_data = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efe88627-4d1b-43e3-8fe8-609f1b35cb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_dashboard = '\"redhat-openshift-ocp-release-4.3-informing\"'\n",
    "selected_job = \"release-openshift-origin-installer-e2e-gcp-compact-4.3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab457b50-b47c-4d04-bb14-1146d4450586",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = testgrid_data[selected_dashboard][selected_job]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "719f9a23-d847-4f87-8a50-c26467845bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = FailureClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e42fcf85-f955-41cc-b45e-d996cc2c2a9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'flaky_tests': '[(6, {(15, 19): 40.0, (23, 27): 40.0}, [(datetime.date(2020, 9, 22), datetime.date(2020, 9, 18)), (datetime.date(2020, 9, 14), datetime.date(2020, 9, 10))])]',\n",
       " 'infra_flake': '[(datetime.date(2020, 10, 2), 1), (datetime.date(2020, 10, 1), 3)]',\n",
       " 'install_flake': '[datetime.date(2020, 9, 2), datetime.date(2020, 8, 31)]',\n",
       " 'new_test_failure': '[]'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c572671-1566-491c-8bd3-0c17bbf999ab",
   "metadata": {},
   "source": [
    "# Save Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8d9e238-81bd-458e-bcd4-f53d0b818e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.joblib']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(classifier, \"model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36ce3674-584d-4abc-acec-1be00fdcbbe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'flaky_tests': '[(6, {(15, 19): 40.0, (23, 27): 40.0}, [(datetime.date(2020, 9, 22), datetime.date(2020, 9, 18)), (datetime.date(2020, 9, 14), datetime.date(2020, 9, 10))])]',\n",
       " 'infra_flake': '[(datetime.date(2020, 10, 2), 1), (datetime.date(2020, 10, 1), 3)]',\n",
       " 'install_flake': '[datetime.date(2020, 9, 2), datetime.date(2020, 8, 31)]',\n",
       " 'new_test_failure': '[]'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check to see if the saved model works locally\n",
    "classifier_dump = joblib.load(\"model.joblib\")\n",
    "classifier_dump.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6f71492-7d73-4454-b2a3-0a8a5ccde749",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Required parameter name not set",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5091/4094899836.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0maws_secret_access_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms3_secret_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m )\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mbucket\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms3_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBucket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms3_bucket\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/app-root/lib64/python3.8/site-packages/boto3/resources/factory.py\u001b[0m in \u001b[0;36mcreate_resource\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    471\u001b[0m                     \u001b[0mpositional_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             return partial(resource_cls, *positional_args,\n\u001b[0m\u001b[1;32m    474\u001b[0m                            client=self.meta.client)(*args, **kwargs)\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/app-root/lib64/python3.8/site-packages/boto3/resources/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midentifier\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentifiers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    119\u001b[0m                     'Required parameter {0} not set'.format(identifier))\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Required parameter name not set"
     ]
    }
   ],
   "source": [
    "s3_resource = boto3.resource(\n",
    "    \"s3\",\n",
    "    endpoint_url=s3_endpoint_url,\n",
    "    aws_access_key_id=s3_access_key,\n",
    "    aws_secret_access_key=s3_secret_key,\n",
    ")\n",
    "bucket = s3_resource.Bucket(name=s3_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaaeb47-fa3e-4625-9f39-bc883bcf3666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload your model\n",
    "bucket.upload_file(\"model.joblib\", \"ai4ci/failure-classifier/model/model.joblib\")\n",
    "\n",
    "# Check if your model exists on s3\n",
    "objects = [\n",
    "    obj.key for obj in bucket.objects.filter(Prefix=\"\") if \"model.joblib\" in obj.key\n",
    "]\n",
    "objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458a173c-ccb4-47b5-ab5f-4f3d666ae644",
   "metadata": {},
   "source": [
    "# Test seldon deployment service \n",
    "We use the deployment [config](seldon_deployment_config.yaml) to deploy a seldon service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93047e57-db7b-4115-8518-f18e22bfe16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Service url\n",
    "base_url = \"placeholder for smaug\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b25431-22a9-4cec-8be5-2042c8fa7e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set (same as locally checked model) testgrid_data, grid, selected_dashboard, selected_job\n",
    "test_list = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9615b8-6e3a-48c8-b967-50971062c4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the dataframe into a numpy array and then to a list (required by seldon)\n",
    "data = {\"data\": {\"ndarray\": test_list}}\n",
    "\n",
    "# create the query payload\n",
    "json_data = json.dumps(data)\n",
    "headers = {\"content-Type\": \"application/json\"}\n",
    "\n",
    "# query our inference service\n",
    "response = requests.post(base_url, data=json_data, headers=headers)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62be7b23-63a0-48cb-8e30-53ff7124e93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f205fc5c-cfd7-4acf-a7c5-67662e03156f",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "In this notebook, we saw how to create and save a method for classifying flakey tests. We successfully deployed and tested the method utilizing S3 storage and a Seldon deployment on Openshift. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef30bca2-064e-47c6-acdd-66b4bee0529b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

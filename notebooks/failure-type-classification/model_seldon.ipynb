{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4392ea3b-9c11-4b33-854a-4d9232279e1a",
   "metadata": {},
   "source": [
    "# Seldon deployment of failure classification\n",
    "In this notebook, we deploy a service for classifying flakes. We take the experiments in the [failure type classifier notebook](failure_type_classifier.ipynb) and train a sklearn pipeline with all the components, store the pipeline on S3, and deploy it using Seldon. Finally, we test the service for inference on an example request. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7231359-8ec1-484a-a36a-a60c5be94932",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import gzip\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import warnings\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from ipynb.fs.defs.failure_type_functions import (\n",
    "    print_report,\n",
    "    detect_failures,\n",
    "    normalize,\n",
    "    format_results,\n",
    "    CephCommunication,\n",
    "    decode_run_length\n",
    ")\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a8940d-288b-4f79-9d9d-9d08bf73d97b",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c09ef83-d7f5-4092-8cae-324d8476f7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Specify variables\n",
    "\n",
    "METRIC_NAME = \"failure_type\"\n",
    "\n",
    "# Specify the path for input grid data\n",
    "INPUT_DATA_PATH = \"../../data/raw/testgrid_810.json.gz\"\n",
    "\n",
    "# Specify the path for output metric data\n",
    "OUTPUT_DATA_PATH = f\"../../data/processed/metrics/{METRIC_NAME}\"\n",
    "\n",
    "## CEPH Bucket variables\n",
    "## Create a .env file on your local with the correct configs\n",
    "s3_endpoint_url = os.getenv(\"S3_ENDPOINT\")\n",
    "s3_access_key = os.getenv(\"S3_ACCESS_KEY\")\n",
    "s3_secret_key = os.getenv(\"S3_SECRET_KEY\")\n",
    "s3_bucket = os.getenv(\"S3_BUCKET\")\n",
    "s3_path = os.getenv(\"S3_PROJECT_KEY\", \"metrics\")\n",
    "s3_input_data_path = \"raw_data\"\n",
    "s3_output_data_path = \"failure_type\"\n",
    "\n",
    "# Specify whether or not we are running this as a notebook or part of an automation pipeline.\n",
    "AUTOMATION = os.getenv(\"IN_AUTOMATION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b3e6b0b-c976-4183-b94b-3b84f242bd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import data\n",
    "timestamp = datetime.datetime.today()\n",
    "filename = f\"testgrid_{timestamp.day}{timestamp.month}.json\"\n",
    "# timestamp = datetime.datetime(2021, 4, 14)\n",
    "\n",
    "if AUTOMATION:\n",
    "    filename = f\"testgrid_{timestamp.day}{timestamp.month}.json\"\n",
    "    cc = CephCommunication(s3_endpoint_url, s3_access_key, s3_secret_key, s3_bucket)\n",
    "    s3_object = cc.s3_resource.Object(s3_bucket, f\"{s3_input_data_path}/{filename}\")\n",
    "    file_content = s3_object.get()[\"Body\"].read().decode(\"utf-8\")\n",
    "    testgrid_data = json.loads(file_content)\n",
    "\n",
    "else:\n",
    "    with gzip.open(INPUT_DATA_PATH, \"rb\") as read_file:\n",
    "        testgrid_data = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efe88627-4d1b-43e3-8fe8-609f1b35cb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_dashboard = '\"redhat-openshift-ocp-release-4.3-informing\"'\n",
    "selected_job = \"release-openshift-origin-installer-e2e-gcp-compact-4.3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb146cf1-6f12-4393-88c3-0ed098105d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = testgrid_data[selected_dashboard][selected_job][\"grid\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "655eaf1d-87ab-4bb1-8bdf-e826b2937876",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(list(pd.DataFrame(grid).statuses.apply(decode_run_length)))\n",
    "x = pd.DataFrame(x).apply(lambda x: [normalize(y) for y in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08f6f2ab-2e85-424b-bfa0-1d9aaa7ef7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = detect_failures(testgrid_data, grid, selected_dashboard, selected_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00b07760-844c-41d3-8814-0b97f0529a49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'flaky_tests': '[(6, {(15, 19): 40.0, (23, 27): 40.0}, [(datetime.date(2020, 9, 22), datetime.date(2020, 9, 18)), (datetime.date(2020, 9, 14), datetime.date(2020, 9, 10))])]',\n",
       " 'infra_flake': '[(datetime.date(2020, 10, 2), 1), (datetime.date(2020, 10, 1), 3)]',\n",
       " 'install_flake': '[datetime.date(2020, 9, 2), datetime.date(2020, 8, 31)]',\n",
       " 'new_test_failure': '[]'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = format_results(results)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c97500a-8ee8-449c-ad58-3a14840a52f2",
   "metadata": {},
   "source": [
    "# Train SKlearn Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76cc0ab6-55b5-4061-aaef-09f56c20283e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FailClassifier:\n",
    "    def __init__(self, testgrid_data, grid, selected_dashboard, selected_job):\n",
    "\n",
    "        self.testgrid_data = testgrid_data\n",
    "        self.grid = grid\n",
    "        self.selected_dashboard = selected_dashboard\n",
    "        self.selected_job = selected_job\n",
    "        print(\">>>>>>>>>>>init>>>>>>>>>>>\")\n",
    "\n",
    "    def fit(self):\n",
    "        print(\">>>>>>>>>>>fit>>>>>>>>>>>\")\n",
    "\n",
    "    def predict(self, testgrid_data, grid, selected_dashboard, selected_job):\n",
    "        results = detect_failures(testgrid_data, grid, selected_dashboard, selected_job)\n",
    "        results = format_results(results)\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7f5161c-74cd-4bf2-b45b-827f1366fc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([(\"fail_classifier\", FailClassifier)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b86c7c3d-7dc0-4c8d-a8f0-51c6a977686b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() missing 1 required positional argument: 'X'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3269/1909854420.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: fit() missing 1 required positional argument: 'X'"
     ]
    }
   ],
   "source": [
    "pipeline.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fecb641-3e74-4e03-8968-bda7789862a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.predict(testgrid_data, grid, selected_dashboard, selected_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c572671-1566-491c-8bd3-0c17bbf999ab",
   "metadata": {},
   "source": [
    "# Save Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d9e238-81bd-458e-bcd4-f53d0b818e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(pipeline, \"model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ce3674-584d-4abc-acec-1be00fdcbbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check to see if the saved model works locally\n",
    "pipeline_loaded = joblib.load(\"model.joblib\")\n",
    "pipeline_loaded\n",
    "pipeline_loaded.predict(build_logs[50:75])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5319ba0e-ae92-47d5-b83a-42a3f6dacd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set credentials for your s3 storage\n",
    "s3_endpoint_url = os.getenv(\"S3_ENDPOINT\")\n",
    "aws_access_key_id = os.getenv(\"S3_ACCESS_KEY\")\n",
    "aws_secret_access_key = os.getenv(\"S3_SECRET_KEY\")\n",
    "s3_bucket = os.getenv(\"S3_BUCKET\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f71492-7d73-4454-b2a3-0a8a5ccde749",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_resource = boto3.resource(\n",
    "    \"s3\",\n",
    "    endpoint_url=s3_endpoint_url,\n",
    "    aws_access_key_id=aws_access_key_id,\n",
    "    aws_secret_access_key=aws_secret_access_key,\n",
    ")\n",
    "bucket = s3_resource.Bucket(name=s3_bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaaeb47-fa3e-4625-9f39-bc883bcf3666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload your model\n",
    "bucket.upload_file(\"model.joblib\", \"failure-classifier/classifier/model.joblib\")\n",
    "\n",
    "# Check if your model exists on s3\n",
    "objects = [\n",
    "    obj.key for obj in bucket.objects.filter(Prefix=\"\") if \"model.joblib\" in obj.key\n",
    "]\n",
    "objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458a173c-ccb4-47b5-ab5f-4f3d666ae644",
   "metadata": {},
   "source": [
    "# Test seldon deployment service \n",
    "We use the deployment [config](seldon_deployment_config.yaml) to deploy a seldon service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93047e57-db7b-4115-8518-f18e22bfe16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Service url\n",
    "# base_url = \"http://failure-classifier-opf-seldon.apps.zero.massopen.cloud/predict\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b25431-22a9-4cec-8be5-2042c8fa7e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set (same as locally checked model) testgrid_data, grid, selected_dashboard, selected_job\n",
    "# test_list = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9615b8-6e3a-48c8-b967-50971062c4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the dataframe into a numpy array and then to a list (required by seldon)\n",
    "data = {\"data\": {\"ndarray\": test_list}}\n",
    "\n",
    "# create the query payload\n",
    "json_data = json.dumps(data)\n",
    "headers = {\"content-Type\": \"application/json\"}\n",
    "\n",
    "# query our inference service\n",
    "response = requests.post(base_url, data=json_data, headers=headers)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62be7b23-63a0-48cb-8e30-53ff7124e93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f205fc5c-cfd7-4acf-a7c5-67662e03156f",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "In this notebook, we saw how to create and save a method for classifying flakey tests. We successfully deployed and tested the method utilizing S3 storage and a Seldon deployment on Openshift. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef30bca2-064e-47c6-acdd-66b4bee0529b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_Analysis",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-SchSDwNCgQ"
      },
      "source": [
        "<H1>Red Hat NLP Spark Project</H1>\n",
        "\n",
        "This notebook uses Red Hat's OpenShift data logs and processes them using Drain3. \n",
        "\n",
        "The first thing this notebook does is webscrape the OpenShift logs and installs dependencies. After, the logs are then cleaned by removing leading tags, dates, timestamps and other unique identifiers. This is done manually because Drain3 does not do this consistently for all logs. Finally the parsed logs are then fed into Drain3 and then put into a dictionary sorted by cluster ID.\n",
        "\n",
        "The final step that needs to be done is to sift out the pass and fail logs based on their cluster ID and visualize our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5cWx89XM9t6",
        "outputId": "0e6ad8e0-73a2-4d65-dd8d-26c2b6912713"
      },
      "source": [
        "!pip3 install drain3\n",
        "!pip3 install kafka-python\n",
        "!pip3 install redis\n",
        "!pip install -q tf-models-official"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting drain3\n",
            "  Downloading https://files.pythonhosted.org/packages/7e/1f/09c4ee7d648b66dda7dc8426e9cf9faeee71e544a2e7700d3d959e5cca59/drain3-0.9.5.tar.gz\n",
            "Collecting jsonpickle==1.5.1\n",
            "  Downloading https://files.pythonhosted.org/packages/77/a7/c2f527ddce3155ae9e008385963c2325cbfd52969f8b38efa2723e2af4af/jsonpickle-1.5.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: cachetools==4.2.1 in /usr/local/lib/python3.7/dist-packages (from drain3) (4.2.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from jsonpickle==1.5.1->drain3) (3.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->jsonpickle==1.5.1->drain3) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->jsonpickle==1.5.1->drain3) (3.7.4.3)\n",
            "Building wheels for collected packages: drain3\n",
            "  Building wheel for drain3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for drain3: filename=drain3-0.9.5-cp37-none-any.whl size=18179 sha256=df021c63200c550dc0982b1034ed467c35c5686e7d82a2590d27a205bb6ec15f\n",
            "  Stored in directory: /root/.cache/pip/wheels/11/a1/08/125223534f199f0db7a435b437015f83abba341ef0f4f6c64f\n",
            "Successfully built drain3\n",
            "Installing collected packages: jsonpickle, drain3\n",
            "Successfully installed drain3-0.9.5 jsonpickle-1.5.1\n",
            "Collecting kafka-python\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/68/dcb0db055309f680ab2931a3eeb22d865604b638acf8c914bedf4c1a0c8c/kafka_python-2.0.2-py2.py3-none-any.whl (246kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 5.8MB/s \n",
            "\u001b[?25hInstalling collected packages: kafka-python\n",
            "Successfully installed kafka-python-2.0.2\n",
            "Collecting redis\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/7c/24fb0511df653cf1a5d938d8f5d19802a88cef255706fdda242ff97e91b7/redis-3.5.3-py2.py3-none-any.whl (72kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 3.2MB/s \n",
            "\u001b[?25hInstalling collected packages: redis\n",
            "Successfully installed redis-3.5.3\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 5.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 174kB 13.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2MB 18.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 5.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 358kB 28.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 706kB 28.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 8.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 645kB 39.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 37.6MB 1.3MB/s \n",
            "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq5k5nqiC02i"
      },
      "source": [
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import dateutil\n",
        "from dateutil import parser\n",
        "import textblob\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "import drain3\n",
        "from drain3 import TemplateMiner\n",
        "import json\n",
        "import logging\n",
        "import sys\n",
        "from drain3.kafka_persistence import KafkaPersistence\n",
        "import re\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "import subprocess\n",
        "import time\n",
        "import spacy\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "import os, os.path\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iq11lna0RAee"
      },
      "source": [
        "#<H3>Dataset</H3>\n",
        "\n",
        "Gather log files from OpenShift and save them to shared google drive, Red Hat & BU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "st2dPqa-UuWF",
        "outputId": "53eb705f-35a1-4a20-8f58-1ff0884534ac"
      },
      "source": [
        "\n",
        "#enable to read files from the google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3plLsNUbQdBo",
        "outputId": "3182b287-4da0-4a2d-e2ca-32062109c696"
      },
      "source": [
        "with open ('/content/drive/MyDrive/RedHat_BU/log/log_file_1.ob', 'rb') as fp:\n",
        "    logs1 = pickle.load(fp)\n",
        "#print(logs[1])\n",
        "\n",
        "with open ('/content/drive/MyDrive/RedHat_BU/label/label_file_1.ob', 'rb') as fp:\n",
        "    labels1 = pickle.load(fp)\n",
        "#print(labels)\n",
        "\n",
        "print(\"number of logs: \", len(logs1))\n",
        "print(\"number of labels: \",len(labels1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of logs:  416\n",
            "number of labels:  416\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fj1i40jxS0MA",
        "outputId": "a1c430d0-ea64-4b23-d857-58805df722b2"
      },
      "source": [
        "#increase data size by twice (416+452=868)\n",
        "with open ('/content/drive/MyDrive/RedHat_BU/log/log_file_2.ob', 'rb') as fp:\n",
        "    logs2 = pickle.load(fp)\n",
        "#print(logs[1])\n",
        "\n",
        "with open ('/content/drive/MyDrive/RedHat_BU/label/label_file_2.ob', 'rb') as fp:\n",
        "    labels2 = pickle.load(fp)\n",
        "#print(labels)\n",
        "print(\"number of logs: \", len(logs2))\n",
        "print(\"number of labels: \",len(labels2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of logs:  452\n",
            "number of labels:  452\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhXs4CqLUs9n",
        "outputId": "5228254b-00a2-44f0-bf2f-bddf283ad303"
      },
      "source": [
        "#increase data size by 3 times (868+2958=3826)\n",
        "with open ('/content/drive/MyDrive/RedHat_BU/log/log_file_3.ob', 'rb') as fp:\n",
        "    logs3 = pickle.load(fp)\n",
        "#print(logs[1])\n",
        "\n",
        "with open ('/content/drive/MyDrive/RedHat_BU/label/label_file_3.ob', 'rb') as fp:\n",
        "    labels3 = pickle.load(fp)\n",
        "#print(labels)\n",
        "print(\"number of logs: \", len(logs3))\n",
        "print(\"number of labels: \",len(labels3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of logs:  2958\n",
            "number of labels:  2958\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvYhITN47N4P",
        "outputId": "a289ff5c-34e5-41c5-802f-c43730f494f2"
      },
      "source": [
        "#increase data size     3826+168=3994\n",
        "with open ('/content/drive/MyDrive/RedHat_BU/log/log_file_4.ob', 'rb') as fp:\n",
        "    logs4 = pickle.load(fp)\n",
        "#print(logs[1])\n",
        "\n",
        "with open ('/content/drive/MyDrive/RedHat_BU/label/label_file_4.ob', 'rb') as fp:\n",
        "    labels4 = pickle.load(fp)\n",
        "#print(labels)\n",
        "print(\"number of logs: \", len(logs4))\n",
        "print(\"number of labels: \",len(labels4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of logs:  168\n",
            "number of labels:  168\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18ETd8BvS3Ne",
        "outputId": "5295f6d3-2b72-42a8-e0e7-007f956c7b02"
      },
      "source": [
        "logs = logs1 + logs2 + logs3 + logs4 \n",
        "labels = labels1 + labels2 + labels3 + labels4 \n",
        "print(\"number of logs: \", len(logs))\n",
        "print(\"number of labels: \",len(labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of logs:  3994\n",
            "number of labels:  3994\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heDQxXYAQzcU"
      },
      "source": [
        "#<H4>Assigning Labels to Logs </H4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S056NuDx71Wt",
        "outputId": "746f27f8-8297-4e0c-f16a-c7d752be02a5"
      },
      "source": [
        "# 1 := success, 0 := fail\n",
        "y = []\n",
        "count_0 = 0\n",
        "count_1 = 0\n",
        "for label in labels:\n",
        "  if label == 'SUCCESS':\n",
        "    y.append(1)\n",
        "    count_1 = count_1 + 1\n",
        "  else:\n",
        "    y.append(0)\n",
        "    count_0 = count_0 + 1\n",
        "print(\"y = \", y)\n",
        "print(\"number of success/1 = \", count_1)\n",
        "print(\"number of fail/0 = \", count_0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y =  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "number of success/1 =  915\n",
            "number of fail/0 =  3079\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pb5gAOrHQ67U"
      },
      "source": [
        "<H4>Splitting log lines for vectorization</H4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BuzkkC0dOamf",
        "outputId": "5e5101ba-45f7-4ad3-bb05-b854ef3bb2b0"
      },
      "source": [
        "vocab = {}\n",
        "i = 0\n",
        "for log in logs:\n",
        "  log = str(log).split(\",\")\n",
        "  for line in log:\n",
        "    line = line.replace(\"'\",\"\").replace(\" \",\"\").replace(\"\\\"\",\"\")\n",
        "    if line not in vocab:\n",
        "      vocab[line] = i\n",
        "      i+=1\n",
        "print(len(vocab))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2176859\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d__aAxaiXGmG"
      },
      "source": [
        "#print(list(vocab.items())[:100])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTYgLuEaRHiX"
      },
      "source": [
        "#<H2>Classifying logs without Drain3 and parsing</H2>\n",
        "\n",
        "Here begins the process of vectorizing each log line and then classifying it as a pass or fail log accordingly. If this cell has an error, run the cell that removes newline characters and the leading b' tag from the logs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUhrDxlNO7JS"
      },
      "source": [
        "vectorizer = TfidfVectorizer(vocabulary = vocab)\n",
        "\n",
        "X = vectorizer.fit_transform(logs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukvCx6NDUhU5",
        "outputId": "b637a258-d80c-412a-cf54-0e0ba065cf6b"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3994, 2176859)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPerlihUQUkT"
      },
      "source": [
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, train_size= 0.8, random_state=1)\n",
        "sss.get_n_splits(X, y)\n",
        "y = np.array(y)\n",
        "for train_index, test_index in sss.split(X, y):\n",
        "  X_train, X_test = X[train_index], X[test_index]\n",
        "  y_train, y_test = y[train_index], y[test_index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjhiyTqNr9Gs",
        "outputId": "8cddfced-1180-4812-aff7-980127a32d85"
      },
      "source": [
        "#tfidf\n",
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3195, 2176859)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJcVgQrOVeI-"
      },
      "source": [
        "# Classifying logs without Drain3 with XGB\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMY0yIo1zt4d"
      },
      "source": [
        "#training accuracy calculator\n",
        "def accuracy_cal(prediction, Testy):\n",
        "    count = 0\n",
        "    for i in range(len(prediction)):\n",
        "        if prediction[i] == int(Testy[i]):\n",
        "            count+=1\n",
        "    accuracy = round(count / len(prediction) * 100, 4)\n",
        "    #print(accuracy, \"%\")\n",
        "    return accuracy\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAm7oirNUc9P",
        "outputId": "2793a834-a20a-4f5c-a81a-4f7711487663"
      },
      "source": [
        "model_XGB = XGBClassifier(scale_pos_weight=99).fit(X_train, y_train)\n",
        "y_test_predictions = model_XGB.predict(X_test)\n",
        "accuracy = accuracy_cal(y_test_predictions, y_test)\n",
        "\n",
        "y_train_predictions = model_XGB.predict(X_train)\n",
        "training_error = mean_squared_error(y_train,y_train_predictions)\n",
        "\n",
        "\n",
        "print(\"=== Confusion Matrix ===\")\n",
        "print(confusion_matrix(y_test, y_test_predictions))\n",
        "\n",
        "print(\"=== Classification Report ===\")\n",
        "print(classification_report(y_test, y_test_predictions))\n",
        "\n",
        "print(\"Training error: \",round(training_error,4))\n",
        "print(\"Training accuracy: \", accuracy,\"%\")\n",
        "print(\"Precision score: {}\".format(precision_score(y_test, y_test_predictions)))\n",
        "print(\"Recall score: {}\".format(recall_score(y_test, y_test_predictions)))\n",
        "print(\"F1 Score: {}\".format(f1_score(y_test, y_test_predictions)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=== Confusion Matrix ===\n",
            "[[605  11]\n",
            " [  0 183]]\n",
            "=== Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99       616\n",
            "           1       0.94      1.00      0.97       183\n",
            "\n",
            "    accuracy                           0.99       799\n",
            "   macro avg       0.97      0.99      0.98       799\n",
            "weighted avg       0.99      0.99      0.99       799\n",
            "\n",
            "Training error:  0.011\n",
            "Training accuracy:  98.6233 %\n",
            "Precision score: 0.9432989690721649\n",
            "Recall score: 1.0\n",
            "F1 Score: 0.9708222811671088\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPdgFG7Da0Pw"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UBShV3kRskG"
      },
      "source": [
        "#<H3>Parsing logs before processing into Drain3</H3>\n",
        "\n",
        "Logs need to be parsed before processing into Drain3. This is necessary because Drain3 does not parse consistently for every log.\n",
        "\n",
        "Things to be parsed:\n",
        "<ul>\n",
        "  <li>Dates</li>\n",
        "  <li>Timestamps</li>\n",
        "  <li>Newline characters</li>\n",
        "  <li>Version numbers</li>\n",
        "  <li>Namespace IDs</li>\n",
        "  <li>URLs</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfWCburJvXQA"
      },
      "source": [
        "original_log = logs[1]\n",
        "#print(original_log)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "aRyol0yU4HP_"
      },
      "source": [
        "#  helper function detecting if a string is a date / timestamp\n",
        "parsed_logs = []\n",
        "def is_date(str):\n",
        "  try:\n",
        "    dateutil.parser.parse(str)\n",
        "    return True\n",
        "  except:\n",
        "    return False\n",
        "for i in range(len(logs)):\n",
        " # splitting each section as its own index (for parsing)\n",
        "  parsed_logs.append(str(logs[i]).split(' '))\n",
        "  for j in range(len(parsed_logs[i])):\n",
        "    if is_date(parsed_logs[i][j]) == True:\n",
        "      parsed_logs[i][j] = ''\n",
        "  parsed_logs[i] = list(filter(lambda x: x != '', parsed_logs[i]))\n",
        "  parsed_logs[i] = ' '.join(parsed_logs[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSINSnQeDqZ9"
      },
      "source": [
        "This code cell removes timestamps and dates in order to mitigate unique identifiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "L8a8Nyc76PQo"
      },
      "source": [
        "for index in range(len(parsed_logs)):\n",
        "  # removing version number\n",
        "  if \"version\" in parsed_logs[index]:\n",
        "    tmp = parsed_logs[index].split(\"version\",1)\n",
        "    tmp_1 = tmp[0]\n",
        "    tmp_2 = tmp[1].split()\n",
        "    tmp_2 = tmp_2[1:]\n",
        "    tmp = ''.join(tmp_1) + ' '.join(tmp_2)\n",
        "    parsed_logs[index] = tmp\n",
        "\n",
        "  # removing creating namespace ID\n",
        "  if \"Creating namespace\" in parsed_logs[index]:\n",
        "    tmp = parsed_logs[index].split(\"Creating namespace\", 1)\n",
        "    tmp_1 = tmp[0]\n",
        "    tmp_2 = tmp[1].split()\n",
        "    tmp_2 = tmp_2[1:]\n",
        "    tmp = ''.join(tmp_1) + ' '.join(tmp_2)\n",
        "    parsed_logs[index] = tmp\n",
        "\n",
        "  # removing using namespace ID\n",
        "  if \"Using namespace\" in parsed_logs[index]:\n",
        "    tmp = parsed_logs[index].split(\"Using namespace\", 1)\n",
        "    tmp_1 = tmp[0]\n",
        "    tmp_2 = tmp[1].split()\n",
        "    tmp_2 = tmp_2[1:]\n",
        "    tmp = ''.join(tmp_1) + ' '.join(tmp_2)\n",
        "    parsed_logs[index] = tmp\n",
        "\n",
        "  # removing Imported release stamp\n",
        "  if \"Imported release\" in parsed_logs[index]:\n",
        "    tmp = parsed_logs[index].split(\"Imported release\", 1)\n",
        "    tmp_1 = tmp[0]\n",
        "    tmp_2 = tmp[1].split()\n",
        "    tmp_2 = tmp_2[1:]\n",
        "    tmp = ''.join(tmp_1) + ' '.join(tmp_2)\n",
        "    parsed_logs[index] = tmp\n",
        "\n",
        "  # removing Acquired lease stamp\n",
        "  if \"Acquired lease\" in parsed_logs[index]:\n",
        "    tmp = parsed_logs[index].split(\"Acquired lease\", 1)\n",
        "    tmp_1 = tmp[0]\n",
        "    tmp_2 = tmp[1].split()\n",
        "    tmp_2 = tmp_2[1:]\n",
        "    tmp = ''.join(tmp_1) + ' '.join(tmp_2)\n",
        "    parsed_logs[index] = tmp\n",
        "\n",
        "  # removing \"images will be pullable from\" link\n",
        "  if \"images will be pullable from\" in parsed_logs[index]:\n",
        "    tmp = parsed_logs[index].split(\"images will be pullable from\", 1)\n",
        "    tmp_1 = tmp[0]\n",
        "    tmp_2 = tmp[1].split()\n",
        "    tmp_2 = tmp_2[1:]\n",
        "    tmp = ''.join(tmp_1) + ' '.join(tmp_2)\n",
        "    parsed_logs[index] = tmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDSHV7fZTOBT"
      },
      "source": [
        "#<H3>Drain3 Processing</H3>\n",
        "\n",
        "The parsed logs are now being processed in Drain3. Drain3 will do additional parsing and also cluster the logs. Drain3 uses longest common subsequence as their algorithm for clustering, so logs with similar structure will be considered to be in the same clustering. There are two dictionaries that represent the size of each cluster and another that separates the logs by cluster ID. The goal of this is to determine which clusters are pass logs and which clusters are fail logs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WtFxnlMOmp3W"
      },
      "source": [
        "\n",
        "template_miner = TemplateMiner(None)\n",
        "i = 0\n",
        "ints_from_drain = []\n",
        "while True:\n",
        "    if i >= len(parsed_logs):\n",
        "      break\n",
        "    log_line = ' '.join(parsed_logs[i])\n",
        "    i += 1\n",
        "    if log_line == 'q':\n",
        "        break\n",
        "    result = template_miner.add_log_message(log_line)\n",
        "    result_json = json.dumps(result)\n",
        "    ints_from_drain.append(re.findall(r'\\d+', result_json))\n",
        "    # print(result_json)\n",
        "\n",
        "ints_from_drain = np.asarray(ints_from_drain)\n",
        "\n",
        "cluster_size = {}\n",
        "cluster_id = {}\n",
        "for cluster in template_miner.drain.clusters:\n",
        "  if cluster.cluster_id not in cluster_size:\n",
        "    cluster_size[cluster.cluster_id] = cluster.size\n",
        "    cluster_id[cluster.cluster_id] = []\n",
        "\n",
        "\n",
        "for i in range(len(ints_from_drain)):\n",
        "  cluster_id[int(ints_from_drain[i][0])].append(parsed_logs[i])\n",
        "\n",
        "print(cluster_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlznByNoD3w1"
      },
      "source": [
        "#<H3>Parsing Results Print out</H3>\n",
        "\n",
        "Here is a snippet example of what the parsing process does to each log. As you can see the leading byte tag, dates, and unique URLs will be parsed out from both manual parsing and Drain3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6rqae9VQDaoS"
      },
      "source": [
        "print(original_log.split(',')[:3])\n",
        "print(parsed_logs[1].split(',')[:3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMuEAdZvVZUX"
      },
      "source": [
        "#<H4>Log cluster example</H4>\n",
        "\n",
        "Here is a printout of logs that fall under a cluster with the ID of 94. This cluster contains the most amount of data logs. Based on the clustering algorithm it is evident that Drain3 uses longest common sequence because all of these logs in this cluster contain the exact same structure with very small differences, especially after being parsed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Rx-UE8x2VXRg"
      },
      "source": [
        "i = 1\n",
        "for log in cluster_id[95]:\n",
        "  print(\"log\", i, \":\",  log[:200], \"...\")\n",
        "  print()\n",
        "  i += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMgfiryITDZ5"
      },
      "source": [
        "#<H2>Classifying logs with Drain3 and parsing</H2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Zm8de6q1RvAx"
      },
      "source": [
        "vocab = {}\n",
        "i = 0\n",
        "hhh = []\n",
        "for log in parsed_logs:\n",
        "  log = str(log).split(\",\")\n",
        "  for line in log:\n",
        "    line = line.replace(\"'\",\"\").replace(\" \",\"\").replace(\"\\\"\",\"\")\n",
        "    if line not in vocab:\n",
        "      vocab[line] = i\n",
        "      i+=1\n",
        "print(len(vocab))\n",
        "# print(hhh)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feNguNBnV7c_"
      },
      "source": [
        "<H4>Vectorizing log lines</H4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "M-7kd8rRR4qL"
      },
      "source": [
        "vectorizer = TfidfVectorizer(vocabulary = vocab)\n",
        "X2 = vectorizer.fit_transform(parsed_logs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LEYrmPmGWeK3"
      },
      "source": [
        "print(X2.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gfJt0J1bR9ir"
      },
      "source": [
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, train_size= 0.8, random_state=1)\n",
        "sss.get_n_splits(X2, y)\n",
        "y = np.array(y)\n",
        "for train_index, test_index in sss.split(X2, y):\n",
        "  X_train2, X_test2 = X2[train_index], X2[test_index]\n",
        "  y_train, y_test = y[train_index], y[test_index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fdOevl5l1Hxt"
      },
      "source": [
        "#tfidf\n",
        "X_train2.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tvepY3kYhXJ"
      },
      "source": [
        "# Classifying logs with Drain3 with XGB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "avuHz_QVYl3_"
      },
      "source": [
        "model_XGB_D = XGBClassifier(scale_pos_weight=99).fit(X_train2, y_train)\n",
        "y_test_predictions = model_XGB_D.predict(X_test2)\n",
        "accuracy = accuracy_cal(y_test_predictions, y_test)\n",
        "\n",
        "y_train_predictions = model_XGB_D.predict(X_train2)\n",
        "training_error = mean_squared_error(y_train,y_train_predictions)\n",
        "\n",
        "\n",
        "print(\"=== Confusion Matrix ===\")\n",
        "print(confusion_matrix(y_test, y_test_predictions))\n",
        "\n",
        "print(\"=== Classification Report ===\")\n",
        "print(classification_report(y_test, y_test_predictions))\n",
        "\n",
        "\n",
        "print(\"Training error: \",round(training_error,4))\n",
        "print(\"Training accuracy: \", accuracy,\"%\")\n",
        "print(\"Precision score: {}\".format(precision_score(y_test, y_test_predictions)))\n",
        "print(\"Recall score: {}\".format(recall_score(y_test, y_test_predictions)))\n",
        "print(\"F1 Score: {}\".format(f1_score(y_test, y_test_predictions)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTiDDkU5Oqy8"
      },
      "source": [
        "#Visualizations\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IuBApuTZEjjW"
      },
      "source": [
        "k = [100,200,300,400,416]\n",
        "#k = [200,400,600,800,868]\n",
        "#k = [700,1400,2100,2800,3500,3826]\n",
        "#k = [500,1000,1500,2000,2500,3000,3500,3994]\n",
        "sdp=[]\n",
        "snp=[]\n",
        "sdf1=[]\n",
        "snf1=[]\n",
        "acc_n = []\n",
        "acc_d = []\n",
        "X[0:k[0]].shape\n",
        "for i in range(len(k)):\n",
        "  DrainX = X[0:k[i]]\n",
        "  NoDrainX = X2[0:k[i]]\n",
        "  lb = y[0:k[i]]\n",
        "  sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, train_size= 0.8, random_state=1)\n",
        "  sss.get_n_splits(DrainX, lb)\n",
        "  lb = np.array(lb)\n",
        "  for train_index, test_index in sss.split(DrainX, lb):\n",
        "    Xd_train, Xd_test = DrainX[train_index], DrainX[test_index]      \n",
        "    Xn_train, Xn_test = NoDrainX[train_index], NoDrainX[test_index]  \n",
        "    y_train, y_test = lb[train_index], lb[test_index]\n",
        "\n",
        "  model_XGB_D = XGBClassifier(scale_pos_weight=99).fit(Xd_train, y_train) \n",
        "  yd_test_predictions = model_XGB_D.predict(Xd_test)\n",
        "  sd_pre = precision_score(y_test, yd_test_predictions)\n",
        "  sdp.append(sd_pre)\n",
        "  sd_f1 = f1_score(y_test, yd_test_predictions)\n",
        "  sdf1.append(sd_f1)\n",
        "  acc_d.append(accuracy_cal(yd_test_predictions, y_test))\n",
        "\n",
        "  model_XGB = XGBClassifier(scale_pos_weight=99).fit(Xn_train, y_train) \n",
        "  yn_test_predictions = model_XGB.predict(Xn_test)\n",
        "  sn_pre = precision_score(y_test, yn_test_predictions)\n",
        "  snp.append(sn_pre)\n",
        "  sn_f1 = f1_score(y_test, yn_test_predictions)\n",
        "  snf1.append(sn_f1)\n",
        "  acc_n.append(accuracy_cal(yn_test_predictions, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "r7TIRdELWein"
      },
      "source": [
        "fig = plt.figure(figsize=(6,8))\n",
        "\n",
        "fig.subplots_adjust(hspace=1.4, wspace=1.4)\n",
        "ax = fig.add_subplot(3, 1, 1)\n",
        "ax.plot(k, acc_d, label = \"XGB_Drain\")\n",
        "ax.plot(k, acc_n, label = \"XGB\")\n",
        "plt.xlabel(\"number of data\")\n",
        "plt.ylabel(\"accuracy\")\n",
        "plt.title('Accuracy of classification for log data with and without processing')\n",
        "plt.legend()\n",
        "\n",
        "ax = fig.add_subplot(3, 1, 2)\n",
        "ax.plot(k, sdp, label = \"XGB\")\n",
        "ax.plot(k, snp, label = \"XGB_Drain\")\n",
        "plt.xlabel(\"number of data\")\n",
        "plt.ylabel(\"precision score\")\n",
        "plt.title('Precision score of classification for log data with and without processing')\n",
        "plt.legend()\n",
        "\n",
        "ax = fig.add_subplot(3, 1, 3)\n",
        "ax.plot(k, sdf1, label = \"XGB_Drain\")\n",
        "ax.plot(k, snf1, label = \"XGB\")\n",
        "plt.xlabel(\"number of data\")\n",
        "plt.ylabel(\"F1 score\")\n",
        "plt.title('F1 score of classification for log data with and without processing')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hth_ioBpm7_7"
      },
      "source": [
        "#<h3>Cross validation</h3>\n",
        "the code below it to verify if there is overfit in our model when the dataset size changes\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZbqDPOQjdTK"
      },
      "source": [
        "#k = [100,200,300,400,416]\n",
        "#k = [200,400,600,800,868]\n",
        "#k = [700,1400,2100,2800,3500,3826]\n",
        "#k = [500,1000,1500,2000,2500,3000,3500,3994]\n",
        "scores_d = [] #Drain\n",
        "scores_s = [] #No Drain\n",
        "for i in range(len(k)):\n",
        "  DrainX = X[0:k[i]]\n",
        "  NoDrainX = X2[0:k[i]]\n",
        "  lb = y[0:k[i]]\n",
        "  cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "  # evaluate model\n",
        "  scores_d.append(np.mean(cross_val_score(model_XGB_D, DrainX, lb, scoring='roc_auc', cv=cv, n_jobs=-1)))\n",
        "  \n",
        "  cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "  # evaluate model\n",
        "  scores_s.append(np.mean(cross_val_score(model_XGB, NoDrainX, lb, scoring='roc_auc', cv=cv, n_jobs=-1)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faXyTLBlj8wE"
      },
      "source": [
        "#fig = plt.figure(figsize=(6,8))\n",
        "\n",
        "\n",
        "plt.plot(k, scores_d, label = \"XGB_Drain\")\n",
        "plt.plot(k, scores_s, label = \"XGB\")\n",
        "plt.xlabel(\"number of data\")\n",
        "plt.ylabel(\"roc_auc\")\n",
        "plt.title('Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) from prediction scores')\n",
        "plt.legend()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
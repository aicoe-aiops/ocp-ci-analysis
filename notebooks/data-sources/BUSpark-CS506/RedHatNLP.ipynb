{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Due 02/28/2021",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-SchSDwNCgQ"
      },
      "source": [
        "<H1>Red Hat NLP Spark Project</H1>\n",
        "\n",
        "This notebook uses Red Hat's OpenShift data logs and processes them using Drain3. \n",
        "\n",
        "The first thing this notebook does is webscrape the OpenShift logs and installs dependencies. After, the logs are then cleaned by removing leading tags, dates, timestamps and other unique identifiers. This is done manually because drain does not do this consistently for all logs. Finally the parsed logs are then fed into Drain3 and then put into a dictionary sorted by cluster ID.\n",
        "\n",
        "The final step that needs to be done is to sift out the pass and fail logs based on their cluster ID and visualize our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5cWx89XM9t6",
        "outputId": "6ee240e0-291d-4449-dda6-1d9209e22091"
      },
      "source": [
        "!pip3 install drain3\n",
        "!pip3 install kafka-python\n",
        "!pip3 install redis"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: drain3 in /usr/local/lib/python3.7/dist-packages (0.9.5)\n",
            "Requirement already satisfied: jsonpickle==1.5.1 in /usr/local/lib/python3.7/dist-packages (from drain3) (1.5.1)\n",
            "Requirement already satisfied: cachetools==4.2.1 in /usr/local/lib/python3.7/dist-packages (from drain3) (4.2.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from jsonpickle==1.5.1->drain3) (3.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->jsonpickle==1.5.1->drain3) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->jsonpickle==1.5.1->drain3) (3.7.4.3)\n",
            "Requirement already satisfied: kafka-python in /usr/local/lib/python3.7/dist-packages (2.0.2)\n",
            "Requirement already satisfied: redis in /usr/local/lib/python3.7/dist-packages (3.5.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq5k5nqiC02i"
      },
      "source": [
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import dateutil\n",
        "from dateutil import parser\n",
        "import textblob\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "import drain3\n",
        "from drain3 import TemplateMiner\n",
        "import json\n",
        "import logging\n",
        "import sys\n",
        "from drain3.kafka_persistence import KafkaPersistence\n",
        "import re\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import subprocess\n",
        "import time\n",
        "import spacy\n",
        "\n",
        "from xgboost import XGBClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iq11lna0RAee"
      },
      "source": [
        "#<H3>Web scraping</H3>\n",
        "\n",
        "Gathers OpenShift using BeautifulSoup and then returns an array containing all of the logs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RT1xSMJ40ewc"
      },
      "source": [
        "# Web scraping \n",
        "# BeautifulSoup for web scraping\n",
        "\n",
        "\n",
        "#url core needed to pull\n",
        "website = \"https://gcsweb-ci.apps.ci.l2s4.p1.openshiftapps.com\"\n",
        "base = \"https://gcsweb-ci.apps.ci.l2s4.p1.openshiftapps.com/gcs/origin-ci-test/logs/canary-release-openshift-origin-installer-e2e-aws-4.5-cnv/\"\n",
        "ending = \"build-log.txt\"\n",
        "finished = \"finished.json\"\n",
        "url = \"https://gcsweb-ci.apps.ci.l2s4.p1.openshiftapps.com/gcs/origin-ci-test/logs/canary-release-openshift-origin-installer-e2e-aws-4.5-cnv/1300557127638585344/build-log.txt\"\n",
        "page = requests.get(base)   \n",
        "data = page.text\n",
        "soup = BeautifulSoup(data)\n",
        "links = []\n",
        "for link in soup.find_all('a'):\n",
        "    links.append(link.get('href'))\n",
        "links = links[1:-1]\n",
        "\n",
        "final_array = []\n",
        "labels_link = []\n",
        "# create array of urls\n",
        "for x in range(len(links)):\n",
        "  final_array.append(str(website) + str(links[x]) + str(ending))\n",
        "  labels_link.append(str(website) + str(links[x]) + str(finished))\n",
        "\n",
        "# pull all urls logs and store in 2-d array where array_of_logs[x] is a build-log file and \n",
        "# array_of_logs[x][y] is an individual log line split by new line\n",
        "array_of_logs = []\n",
        "for x in range(len(final_array)):\n",
        "  page = urlopen(final_array[x])\n",
        "  html_bytes = page.read()\n",
        "  array_of_logs.append(str(html_bytes).split('\\\\n'))\n",
        "  \n",
        "# first log\n",
        "# print(len(lab))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaYWmzJoL1NL"
      },
      "source": [
        "#url core needed to pull\n",
        "website2 = \"https://gcsweb-ci.apps.ci.l2s4.p1.openshiftapps.com\"\n",
        "base2 = \"https://gcsweb-ci.apps.ci.l2s4.p1.openshiftapps.com/gcs/origin-ci-test/logs/release-openshift-ocp-installer-e2e-aws-serial-4.1/\"\n",
        "ending2 = \"build-log.txt\"\n",
        "finished2 = \"finished.json\"\n",
        "page2 = requests.get(base2)    \n",
        "data2 = page2.text\n",
        "soup2 = BeautifulSoup(data2)\n",
        "links2 = []\n",
        "for link2 in soup2.find_all('a'):\n",
        "    links2.append(link2.get('href'))\n",
        "links2 = links2[1:-1]\n",
        "\n",
        "final_array2 = []\n",
        "labels_link2 = []\n",
        "# create array of urls\n",
        "for x in range(len(links2)):\n",
        "  final_array2.append(str(website2) + str(links2[x]) + str(ending2))\n",
        "  labels_link2.append(str(website2) + str(links2[x]) + str(finished2))\n",
        "\n",
        "# pull all urls logs and store in 2-d array where array_of_logs[x] is a build-log file and \n",
        "# array_of_logs[x][y] is an individual log line split by new line\n",
        "array_of_logs2 = []\n",
        "for x in range(len(final_array2)):\n",
        "  page2 = urlopen(final_array2[x])\n",
        "  html_bytes2 = page2.read()\n",
        "  array_of_logs2.append(str(html_bytes2).split('\\\\n'))\n",
        "  \n",
        "# first log\n",
        "# print(array_of_logs2[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGNoRQkn7j3E"
      },
      "source": [
        "# IMPORTANT\n",
        "\n",
        "Run this cell below a few time in a row in order for it to completely remove all the necessary things it is supposed to remove."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsfDoHsxQmqH"
      },
      "source": [
        "for i in range(len(array_of_logs2)):\n",
        "  #  removing newline characters\n",
        "  array_of_logs2[i] = str(array_of_logs2[i]).replace('\\\\n', ' ')\n",
        "  \n",
        " # removes leading 'b from log\n",
        "  array_of_logs2[i] = array_of_logs2[i][2:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqeBizbVQn6m"
      },
      "source": [
        "This code cell above removes newline characters and leading byte signature"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heDQxXYAQzcU"
      },
      "source": [
        "<H4>Assigning Labels to Logs </H4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nX15zcw5v8_z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c366686b-6091-4909-a281-eaf0ec47723b"
      },
      "source": [
        "labels= []\n",
        "index = 0\n",
        "to_remove = []\n",
        "\n",
        "for x in range(len(labels_link)):\n",
        "    page = urlopen(labels_link[x])\n",
        "    data = json.load(page) \n",
        "    labels.append(data[\"result\"])\n",
        "    index += 1\n",
        "\n",
        "for x in range(len(labels_link2)):\n",
        "    page = urlopen(labels_link2[x])\n",
        "    try:\n",
        "      data = json.load(page)\n",
        "      labels.append(data[\"result\"])\n",
        "    except:\n",
        "      to_remove.append(index)\n",
        "      continue\n",
        "    index += 1\n",
        "\n",
        "array_of_logs2 = array_of_logs + array_of_logs2\n",
        "\n",
        "for i in range(len(array_of_logs2)):\n",
        "    if i in to_remove:\n",
        "      array_of_logs2[i] = None\n",
        "array_of_logs2 = [log for log in array_of_logs2 if log != None]\n",
        "print(labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'FAILURE', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'FAILURE', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'FAILURE', 'SUCCESS', 'FAILURE', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'FAILURE', 'FAILURE', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'FAILURE', 'SUCCESS', 'SUCCESS', 'FAILURE', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'FAILURE', 'FAILURE', 'FAILURE', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'error', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'FAILURE', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'FAILURE', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'FAILURE', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'FAILURE', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'FAILURE', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'FAILURE', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'FAILURE', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'FAILURE', 'SUCCESS', 'SUCCESS', 'FAILURE', 'SUCCESS', 'FAILURE', 'SUCCESS', 'SUCCESS', 'FAILURE', 'SUCCESS', 'FAILURE', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'FAILURE', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'FAILURE', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS', 'SUCCESS']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pb5gAOrHQ67U"
      },
      "source": [
        "<H4>Splitting log lines for vectorization</H4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuzkkC0dOamf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69c1b01e-c1fc-4f7d-ed57-79d692afba49"
      },
      "source": [
        "vocab = {}\n",
        "i = 0\n",
        "for log in array_of_logs2:\n",
        "  log = str(log).split(\",\")\n",
        "  for line in log:\n",
        "    if line not in vocab:\n",
        "      vocab[line] = i\n",
        "      i+=1\n",
        "print(len(vocab))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40194\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S056NuDx71Wt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "406ba435-44bb-406e-fd32-56fe080cd9ed"
      },
      "source": [
        "# 1 := success, 0 := fail\n",
        "y = []\n",
        "count_0 = 0\n",
        "count_1 = 0\n",
        "for label in labels:\n",
        "  if label == 'SUCCESS':\n",
        "    y.append(1)\n",
        "    count_1 = count_1 + 1\n",
        "  else:\n",
        "    y.append(0)\n",
        "    count_0 = count_0 + 1\n",
        "print(\"y = \", y)\n",
        "print(\"number of success = \", count_1)\n",
        "print(\"number of fail = \", count_0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y =  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "number of success =  140\n",
            "number of fail =  115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTYgLuEaRHiX"
      },
      "source": [
        "#<H2>Classifying logs without drain and parsing</H2>\n",
        "\n",
        "Here begins the process of vectorizing each log line and then classifying it as a pass or fail log accordingly. If this cell has an error, run the cell that removes newline characters and the leading b' tag from the logs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ya-78Qo8uQG"
      },
      "source": [
        "total = []\n",
        "for log in array_of_logs2:\n",
        "  s = \", \".join(log)\n",
        "  total.append(s)\n",
        "#print(total)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUhrDxlNO7JS"
      },
      "source": [
        "\n",
        "vectorizer = TfidfVectorizer(vocabulary = vocab)\n",
        "X = vectorizer.fit_transform(total)\n",
        "#X = vectorizer.fit_transform(array_of_logs2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukvCx6NDUhU5",
        "outputId": "b02983b9-ebb4-43cb-8bae-5b1540b3e030"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<255x40194 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 0 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPerlihUQUkT"
      },
      "source": [
        "\n",
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, train_size= 0.8, random_state=1)\n",
        "sss.get_n_splits(X, y)\n",
        "y = np.array(y)\n",
        "for train_index, test_index in sss.split(X, y):\n",
        "  X_train, X_test = X[train_index], X[test_index]\n",
        "  y_train, y_test = y[train_index], y[test_index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTD6hq0FHKsv"
      },
      "source": [
        "Manual splitting to see how classifier is working"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHsry0a-6IuU"
      },
      "source": [
        "X_train = X[:100]\n",
        "y_train = y[:100]\n",
        "X_test = X[100:]\n",
        "y_test = y[100:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHF3xkjM3_my"
      },
      "source": [
        "#<H4>Classifying logs without Drain with Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Y-0e2p9Qa4J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f8b8e64-cadb-408c-9c24-38cbf53f8f69"
      },
      "source": [
        "\n",
        "model_RF = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, min_samples_split=2,\n",
        "                               min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, \n",
        "                               max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, \n",
        "                               bootstrap=True, oob_score=False, n_jobs=None, random_state=1, verbose=0, \n",
        "                               warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None).fit(X_train, y_train)\n",
        "\n",
        "                              \n",
        "\n",
        "y_test_predictions = model_RF.predict(X_test)\n",
        "print(\"=== Confusion Matrix ===\")\n",
        "print(confusion_matrix(y_test, y_test_predictions))\n",
        "\n",
        "print(\"=== Classification Report ===\")\n",
        "print(classification_report(y_test, y_test_predictions))\n",
        "\n",
        "\n",
        "print(\"y_test_predictions\", y_test_predictions)\n",
        "\n",
        "#print(\"RMSE on testing set = \", mean_squared_error(y_test, y_test_predictions))\n",
        "\n",
        "#print(\"Accuracy on testing set = \",accuracy_score(y_test, y_test_predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=== Confusion Matrix ===\n",
            "[[ 25   0]\n",
            " [130   0]]\n",
            "=== Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.16      1.00      0.28        25\n",
            "           1       0.00      0.00      0.00       130\n",
            "\n",
            "    accuracy                           0.16       155\n",
            "   macro avg       0.08      0.50      0.14       155\n",
            "weighted avg       0.03      0.16      0.04       155\n",
            "\n",
            "y_test_predictions [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNJ2QKS0CW6r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a0a5ff2-76f1-4339-f81b-d28d051b4bb4"
      },
      "source": [
        "\n",
        "print(\"Precision score: {}\".format(precision_score(y_test, y_test_predictions)))\n",
        "print(\"Recall score: {}\".format(recall_score(y_test, y_test_predictions)))\n",
        "print(\"F1 Score: {}\".format(f1_score(y_test, y_test_predictions)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision score: 0.0\n",
            "Recall score: 0.0\n",
            "F1 Score: 0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJcVgQrOVeI-"
      },
      "source": [
        "# Classifying logs with Drain with XGB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAm7oirNUc9P",
        "outputId": "21a62e1d-b177-4317-cfa6-4e9101e2f73d"
      },
      "source": [
        "model_XGB = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
        "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
        "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
        "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
        "              nthread=None, objective='binary:logistic', random_state=0,\n",
        "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
        "              silent=None, subsample=1, verbosity=1).fit(X_train, y_train)\n",
        "y_test_predictions = model_XGB.predict(X_test)\n",
        "\n",
        "print(\"=== Confusion Matrix ===\")\n",
        "print(confusion_matrix(y_test, y_test_predictions))\n",
        "\n",
        "print(\"=== Classification Report ===\")\n",
        "print(classification_report(y_test, y_test_predictions))\n",
        "\n",
        "print(\"y_test_predictions\", y_test_predictions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=== Confusion Matrix ===\n",
            "[[ 0 23]\n",
            " [ 0 28]]\n",
            "=== Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        23\n",
            "           1       0.55      1.00      0.71        28\n",
            "\n",
            "    accuracy                           0.55        51\n",
            "   macro avg       0.27      0.50      0.35        51\n",
            "weighted avg       0.30      0.55      0.39        51\n",
            "\n",
            "y_test_predictions [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9xcckuXVmVf",
        "outputId": "b5329ae4-71ec-409c-ee28-b5cd688d7459"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=== Confusion Matrix ===\n",
            "[[ 0 23]\n",
            " [ 0 28]]\n",
            "=== Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        23\n",
            "           1       0.55      1.00      0.71        28\n",
            "\n",
            "    accuracy                           0.55        51\n",
            "   macro avg       0.27      0.50      0.35        51\n",
            "weighted avg       0.30      0.55      0.39        51\n",
            "\n",
            "y_test_predictions [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emguFkVCWH-w",
        "outputId": "4749c4f6-e6e9-4657-a7af-b2c7ef69e262"
      },
      "source": [
        "print(\"Precision score: {}\".format(precision_score(y_test, y_test_predictions)))\n",
        "print(\"Recall score: {}\".format(recall_score(y_test, y_test_predictions)))\n",
        "print(\"F1 Score: {}\".format(f1_score(y_test, y_test_predictions)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision score: 0.5490196078431373\n",
            "Recall score: 1.0\n",
            "F1 Score: 0.7088607594936709\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UBShV3kRskG"
      },
      "source": [
        "#<H3>Log Parsing</H3>\n",
        "\n",
        "Logs need to be parsed before processing into drain. This is necessary because drain does not parse consistently for every log.\n",
        "\n",
        "Things to be parsed:\n",
        "<ul>\n",
        "  <li>Dates</li>\n",
        "  <li>Timestamps</li>\n",
        "  <li>Newline characters</li>\n",
        "  <li>Version numbers</li>\n",
        "  <li>Namespace IDs</li>\n",
        "  <li>URLs</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDM9A5aB2wSl"
      },
      "source": [
        "original_log = array_of_logs2[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRyol0yU4HP_"
      },
      "source": [
        "#  helper function detecting if a string is a date / timestamp\n",
        "def is_date(str):\n",
        "  try:\n",
        "    dateutil.parser.parse(str)\n",
        "    return True\n",
        "  except:\n",
        "    return False\n",
        "for i in range(len(array_of_logs2)):\n",
        " # splitting each section as its own index (for parsing)\n",
        "  array_of_logs2[i] = str(array_of_logs2[i]).split(' ')\n",
        "  for j in range(len(array_of_logs2[i])):\n",
        "    if is_date(array_of_logs2[i][j]) == True:\n",
        "      array_of_logs2[i][j] = ''\n",
        "  array_of_logs2[i] = list(filter(lambda x: x != '', array_of_logs2[i]))\n",
        "  array_of_logs2[i] = ' '.join(array_of_logs2[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSINSnQeDqZ9"
      },
      "source": [
        "This code cell removes timestamps and dates in order to mitigate unique identifiers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8a8Nyc76PQo"
      },
      "source": [
        "for index in range(len(array_of_logs2)):\n",
        "  # removing version number\n",
        "  if \"version\" in array_of_logs2[index]:\n",
        "    tmp = array_of_logs2[index].split(\"version\",1)\n",
        "    tmp_1 = tmp[0]\n",
        "    tmp_2 = tmp[1].split()\n",
        "    tmp_2 = tmp_2[1:]\n",
        "    tmp = ''.join(tmp_1) + ' '.join(tmp_2)\n",
        "    array_of_logs2[index] = tmp\n",
        "\n",
        "  # removing creating namespace ID\n",
        "  if \"Creating namespace\" in array_of_logs2[index]:\n",
        "    tmp = array_of_logs2[index].split(\"Creating namespace\", 1)\n",
        "    tmp_1 = tmp[0]\n",
        "    tmp_2 = tmp[1].split()\n",
        "    tmp_2 = tmp_2[1:]\n",
        "    tmp = ''.join(tmp_1) + ' '.join(tmp_2)\n",
        "    array_of_logs2[index] = tmp\n",
        "\n",
        "  # removing using namespace ID\n",
        "  if \"Using namespace\" in array_of_logs2[index]:\n",
        "    tmp = array_of_logs2[index].split(\"Using namespace\", 1)\n",
        "    tmp_1 = tmp[0]\n",
        "    tmp_2 = tmp[1].split()\n",
        "    tmp_2 = tmp_2[1:]\n",
        "    tmp = ''.join(tmp_1) + ' '.join(tmp_2)\n",
        "    array_of_logs2[index] = tmp\n",
        "\n",
        "  # removing Imported release stamp\n",
        "  if \"Imported release\" in array_of_logs2[index]:\n",
        "    tmp = array_of_logs2[index].split(\"Imported release\", 1)\n",
        "    tmp_1 = tmp[0]\n",
        "    tmp_2 = tmp[1].split()\n",
        "    tmp_2 = tmp_2[1:]\n",
        "    tmp = ''.join(tmp_1) + ' '.join(tmp_2)\n",
        "    array_of_logs2[index] = tmp\n",
        "\n",
        "  # removing Acquired lease stamp\n",
        "  if \"Acquired lease\" in array_of_logs2[index]:\n",
        "    tmp = array_of_logs2[index].split(\"Acquired lease\", 1)\n",
        "    tmp_1 = tmp[0]\n",
        "    tmp_2 = tmp[1].split()\n",
        "    tmp_2 = tmp_2[1:]\n",
        "    tmp = ''.join(tmp_1) + ' '.join(tmp_2)\n",
        "    array_of_logs2[index] = tmp\n",
        "\n",
        "  # removing \"images will be pullable from\" link\n",
        "  if \"images will be pullable from\" in array_of_logs2[index]:\n",
        "    tmp = array_of_logs2[index].split(\"images will be pullable from\", 1)\n",
        "    tmp_1 = tmp[0]\n",
        "    tmp_2 = tmp[1].split()\n",
        "    tmp_2 = tmp_2[1:]\n",
        "    tmp = ''.join(tmp_1) + ' '.join(tmp_2)\n",
        "    array_of_logs2[index] = tmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35RiS8Y2S3Yn"
      },
      "source": [
        "This code cell is removing any unique identifiers such as version numbers, URLs and namespace IDs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDSHV7fZTOBT"
      },
      "source": [
        "#<H3>Drain3 Processing</H3>\n",
        "\n",
        "The parsed logs are now being processed in Drain. Drain will do additional parsing and also cluster the logs. Drain uses longest common subsequence as their algorithm for clustering, so logs with similar structure will be considered to be in the same clustering. There are two dictionaries that represent the size of each cluster and another that separates the logs by cluster ID. The goal of this is to determine which clusters are pass logs and which clusters are fail logs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtFxnlMOmp3W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8bd9533-0386-4113-f646-78016b860612"
      },
      "source": [
        "\n",
        "template_miner = TemplateMiner(None)\n",
        "i = 0\n",
        "ints_from_drain = []\n",
        "while True:\n",
        "    if i >= len(array_of_logs2):\n",
        "      break\n",
        "    log_line = ' '.join(array_of_logs2[i])\n",
        "    i += 1\n",
        "    if log_line == 'q':\n",
        "        break\n",
        "    result = template_miner.add_log_message(log_line)\n",
        "    result_json = json.dumps(result)\n",
        "    ints_from_drain.append(re.findall(r'\\d+', result_json))\n",
        "    # print(result_json)\n",
        "\n",
        "ints_from_drain = np.asarray(ints_from_drain)\n",
        "\n",
        "cluster_size = {}\n",
        "cluster_id = {}\n",
        "for cluster in template_miner.drain.clusters:\n",
        "  if cluster.cluster_id not in cluster_size:\n",
        "    cluster_size[cluster.cluster_id] = cluster.size\n",
        "    cluster_id[cluster.cluster_id] = []\n",
        "\n",
        "\n",
        "for i in range(len(ints_from_drain)):\n",
        "  cluster_id[int(ints_from_drain[i][0])].append(array_of_logs2[i])\n",
        "\n",
        "print(cluster_size)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting Drain3 template miner\n",
            "Loading configuration from drain3.ini\n",
            "config file not found: drain3.ini\n",
            "{1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1, 10: 1, 11: 1, 12: 2, 13: 1, 14: 1, 15: 1, 16: 1, 17: 1, 18: 1, 19: 1, 20: 1, 21: 1, 22: 1, 23: 1, 24: 1, 25: 1, 26: 1, 27: 1, 28: 1, 29: 1, 30: 1, 31: 1, 32: 1, 33: 1, 34: 1, 35: 1, 36: 1, 37: 1, 38: 1, 39: 1, 40: 1, 41: 1, 42: 1, 43: 1, 44: 1, 45: 1, 46: 1, 47: 1, 48: 1, 49: 1, 50: 1, 51: 1, 52: 1, 53: 1, 54: 1, 55: 1, 56: 1, 57: 1, 58: 1, 59: 1, 60: 1, 61: 1, 62: 1, 63: 1, 64: 1, 65: 1, 66: 1, 67: 1, 68: 1, 69: 1, 70: 1, 71: 1, 72: 1, 73: 1, 74: 1, 75: 1, 76: 1, 77: 1, 78: 1, 79: 1, 80: 1, 81: 1, 82: 1, 83: 1, 84: 1, 85: 1, 86: 1, 87: 1, 88: 1, 89: 1, 90: 6, 91: 2, 92: 8, 93: 5, 94: 1, 95: 5, 96: 1, 97: 2, 98: 1, 99: 1, 100: 6, 101: 1, 102: 1, 103: 1, 104: 3, 105: 1, 106: 1, 107: 1, 108: 1, 109: 17, 110: 1, 111: 1, 112: 1, 113: 1, 114: 3, 115: 1, 116: 1, 117: 1, 118: 10, 119: 1, 120: 1, 121: 1, 122: 1, 123: 1, 124: 3, 125: 1, 126: 3, 127: 2, 128: 37, 129: 4, 130: 1, 131: 1, 132: 1, 133: 1, 134: 3, 135: 2, 136: 1, 137: 1, 138: 1, 139: 1, 140: 1, 141: 1, 142: 1, 143: 2, 144: 1, 145: 1, 146: 1, 147: 2, 148: 1, 149: 1}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlznByNoD3w1"
      },
      "source": [
        "#<H3>Parsing Results Print out</H3>\n",
        "\n",
        "Here is a snippet example of what the parsing process does to each log. As you can see the leading byte tag, dates, and unique URLs will be parsed out from both manual parsing and Drain."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rqae9VQDaoS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce204dd8-70cc-470c-8059-702256e6ca85"
      },
      "source": [
        "# print(original_log.split(',')[:3])\n",
        "print(array_of_logs2[1].split(',')[:3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['[\"b\\'2020/10/26 ci-operator No source defined\\'', \" Resolved release latest to registry.svc.ci.openshift.org/ocp/release:4.5-ci'\", ' Running [release-inputs]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6exsz7srB2en"
      },
      "source": [
        "<H3>Number of unique logs</H3>\n",
        "Passed 266 logs into Drain, it returned 155 unique clusters after that."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMuEAdZvVZUX"
      },
      "source": [
        "#<H4>Log cluster example</H4>\n",
        "\n",
        "Here is a printout of logs that fall under a cluster with the ID of 94. This cluster contains the most amount of data logs. Based on the clustering algorithm it is evident that drain uses longest common sequence because all of these logs in this cluster contain the exact same structure with very small differences, especially after being parsed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rx-UE8x2VXRg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "604e45ec-2a2a-4d0e-d020-6418cb56fde0"
      },
      "source": [
        "i = 1\n",
        "for log in cluster_id[95]:\n",
        "  print(\"log\", i, \":\",  log[:200], \"...\")\n",
        "  print()\n",
        "  i += 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "log 1 : b'2020/11/10 ci-operator No source defined', Resolved release latest to registry.svc.ci.openshift.org/ocp/release:4.1', warning: overriding parameter \"LEASED_RESOURCE\"', Running [release-inputs], e2e- ...\n",
            "\n",
            "log 2 : b'2020/11/11 ci-operator No source defined', Resolved release latest to registry.svc.ci.openshift.org/ocp/release:4.1', warning: overriding parameter \"LEASED_RESOURCE\"', Running [release-inputs], e2e- ...\n",
            "\n",
            "log 3 : b'2020/11/12 ci-operator No source defined', Resolved release latest to registry.svc.ci.openshift.org/ocp/release:4.1', warning: overriding parameter \"LEASED_RESOURCE\"', Running [release-inputs], e2e- ...\n",
            "\n",
            "log 4 : b'2020/11/13 ci-operator No source defined', Resolved release latest to registry.svc.ci.openshift.org/ocp/release:4.1', warning: overriding parameter \"LEASED_RESOURCE\"', Running [release-inputs], e2e- ...\n",
            "\n",
            "log 5 : b'2020/11/15 ci-operator No source defined', Resolved release latest to registry.svc.ci.openshift.org/ocp/release:4.1', warning: overriding parameter \"LEASED_RESOURCE\"', Running [release-inputs], e2e- ...\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMgfiryITDZ5"
      },
      "source": [
        "#<H2>Classifying logs with Drain and parsing</H2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zm8de6q1RvAx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2952ca0d-26e3-4c0b-be97-4a86704a3c21"
      },
      "source": [
        "vocab = {}\n",
        "i = 0\n",
        "hhh = []\n",
        "for log in array_of_logs2:\n",
        "  log = str(log).split(\",\")\n",
        "  for line in log:\n",
        "    if line not in vocab:\n",
        "      vocab[line] = i\n",
        "      i+=1\n",
        "      hhh.append(line)\n",
        "print(len(vocab))\n",
        "# print(hhh)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "27449\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feNguNBnV7c_"
      },
      "source": [
        "<H4>Vectorizing log lines</H4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-7kd8rRR4qL"
      },
      "source": [
        "\n",
        "vectorizer = TfidfVectorizer(vocabulary = vocab)\n",
        "X = vectorizer.fit_transform(hhh)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfJt0J1bR9ir"
      },
      "source": [
        "\n",
        "vectorizer = TfidfVectorizer(vocabulary = vocab)\n",
        "X = vectorizer.fit_transform(total)\n",
        "\n",
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, train_size= 0.8, random_state=1)\n",
        "sss.get_n_splits(X, y)\n",
        "y = np.array(y)\n",
        "for train_index, test_index in sss.split(X, y):\n",
        "  X_train, X_test = X[train_index], X[test_index]\n",
        "  y_train, y_test = y[train_index], y[test_index]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4sxG2SiWB0_"
      },
      "source": [
        "#<H4>Classifying logs with Drain with Random Forest Classifier</H4>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bpp7dguESDXu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e770ea30-fda4-4e2b-8da4-3298b70ab300"
      },
      "source": [
        "\n",
        "model_RF_D = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=None, min_samples_split=2,\n",
        "                               min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, \n",
        "                               max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, \n",
        "                               bootstrap=True, oob_score=False, n_jobs=None, random_state=1, verbose=0, \n",
        "                               warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None).fit(X_train, y_train)\n",
        "                              \n",
        "y_test_predictions = model_XGB.predict(X_test)\n",
        "\n",
        "print(\"=== Confusion Matrix ===\")\n",
        "print(confusion_matrix(y_test, y_test_predictions))\n",
        "\n",
        "print(\"=== Classification Report ===\")\n",
        "print(classification_report(y_test, y_test_predictions))\n",
        "\n",
        "print(\"y_test_predictions\", y_test_predictions)\n",
        "#print(\"RMSE on testing set = \", mean_squared_error(y_test, y_test_predictions))\n",
        "\n",
        "\n",
        "#print(\"Accuracy on testing set = \",accuracy_score(y_test, y_test_predictions))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=== Confusion Matrix ===\n",
            "[[ 0 23]\n",
            " [ 0 28]]\n",
            "=== Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        23\n",
            "           1       0.55      1.00      0.71        28\n",
            "\n",
            "    accuracy                           0.55        51\n",
            "   macro avg       0.27      0.50      0.35        51\n",
            "weighted avg       0.30      0.55      0.39        51\n",
            "\n",
            "y_test_predictions [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l76BXBD0CnP2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fb703c3-9162-4508-c949-888e662d4ada"
      },
      "source": [
        "\n",
        "print(\"Precision score: {}\".format(precision_score(y_test, y_test_predictions)))\n",
        "print(\"Recall score: {}\".format(recall_score(y_test, y_test_predictions)))\n",
        "print(\"F1 Score: {}\".format(f1_score(y_test, y_test_predictions)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Precision score: 0.5490196078431373\n",
            "Recall score: 1.0\n",
            "F1 Score: 0.7088607594936709\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tvepY3kYhXJ"
      },
      "source": [
        "# Classifying logs with Drain with XGB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avuHz_QVYl3_",
        "outputId": "f72e4fe7-4902-40ef-a0b4-f5e0c725d875"
      },
      "source": [
        "model_XGB_D = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
        "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
        "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
        "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
        "              nthread=None, objective='binary:logistic', random_state=0,\n",
        "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
        "              silent=None, subsample=1, verbosity=1).fit(X_train, y_train)\n",
        "y_test_predictions = model_XGB_D.predict(X_test)\n",
        "print(\"=== Confusion Matrix ===\")\n",
        "print(confusion_matrix(y_test, y_test_predictions))\n",
        "\n",
        "print(\"=== Classification Report ===\")\n",
        "print(classification_report(y_test, y_test_predictions))\n",
        "print(\"y_test_predictions\", y_test_predictions)\n",
        "\n",
        "print(\"Precision score: {}\".format(precision_score(y_test, y_test_predictions)))\n",
        "print(\"Recall score: {}\".format(recall_score(y_test, y_test_predictions)))\n",
        "print(\"F1 Score: {}\".format(f1_score(y_test, y_test_predictions)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=== Confusion Matrix ===\n",
            "[[ 0 23]\n",
            " [ 0 28]]\n",
            "=== Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        23\n",
            "           1       0.55      1.00      0.71        28\n",
            "\n",
            "    accuracy                           0.55        51\n",
            "   macro avg       0.27      0.50      0.35        51\n",
            "weighted avg       0.30      0.55      0.39        51\n",
            "\n",
            "y_test_predictions [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "Precision score: 0.5490196078431373\n",
            "Recall score: 1.0\n",
            "F1 Score: 0.7088607594936709\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtfC_gaeGv8v"
      },
      "source": [
        "#Gnerate clusters and a prefix tree\n",
        "The cell below runs the drain3 program. Process the log info and generate clusters and a prefix tree of the log information."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cb0-1Ou6EYbx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e89796b-6cc9-4f5c-e5ef-52b6e07c21ce"
      },
      "source": [
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO, format='%(message)s')\n",
        "\n",
        "template_miner = TemplateMiner()\n",
        "\n",
        "line_count = 0\n",
        "start_time = time.time()\n",
        "batch_start_time = start_time\n",
        "batch_size = 10000\n",
        "for i in range(len(array_of_logs2)):\n",
        "  for line in array_of_logs2[i]:\n",
        "      line = line.rstrip()\n",
        "      line = line.partition(\": \")[2]\n",
        "      result = template_miner.add_log_message(line)\n",
        "      line_count += 1\n",
        "      if line_count % batch_size == 0:\n",
        "          time_took = time.time() - batch_start_time\n",
        "          rate = batch_size / time_took\n",
        "          # logger.info(f\"Processing line: {line_count}, rate {rate:.1f} lines/sec, \"\n",
        "          #             f\"{len(template_miner.drain.clusters)} clusters so far.\")\n",
        "          batch_start_time = time.time()\n",
        "      if result[\"change_type\"] != \"none\":\n",
        "          result_json = json.dumps(result)\n",
        "          logger.info(f\"Input ({line_count}): \" + line)\n",
        "          logger.info(\"Result: \" + result_json)\n",
        "\n",
        "time_took = time.time() - start_time\n",
        "rate = line_count / time_took\n",
        "logger.info(f\"--- Done processing file. Total of {line_count} lines, rate {rate:.1f} lines/sec, \"\n",
        "            f\"{len(template_miner.drain.clusters)} clusters\")\n",
        "sorted_clusters = sorted(template_miner.drain.clusters, key=lambda it: it.size, reverse=True)\n",
        "for cluster in sorted_clusters:\n",
        "    logger.info(cluster)\n",
        "\n",
        "print(\"Prefix Tree:\")\n",
        "template_miner.drain.print_tree()\n",
        "\n",
        "template_miner.profiler.report(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting Drain3 template miner\n",
            "Loading configuration from drain3.ini\n",
            "config file not found: drain3.ini\n",
            "Input (1): \n",
            "Result: {\"change_type\": \"cluster_created\", \"cluster_id\": 1, \"cluster_size\": 1, \"template_mined\": \"\", \"cluster_count\": 1}\n",
            "--- Done processing file. Total of 8593683 lines, rate 141959.9 lines/sec, 1 clusters\n",
            "ID=1     : size=8593683   : \n",
            "Prefix Tree:\n",
            "<root>\n",
            "\t<0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4HDylvOFVLQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
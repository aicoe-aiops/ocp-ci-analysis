{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantify Flakes\n",
    "\n",
    "One of the key perfomance indicators that we would like to create greater visbility into and track over time is overall number and percent of flakes that occur. Individual test runs are flagged a \"flake\" if they are run mulitple times with a mix of passes and failes without any changes to the code being tested. Although they occur for individual test runs, there are a number of aggregate views that developers may want to look at to assess the overall health of thier project or testing platform. For Example:\n",
    "\n",
    "* percent flakes on platform each day\n",
    "* percent flakes by tab each week\n",
    "* percent flakes by grid each month\n",
    "* percent flakes by test overall (this can also be seen as a severity level = overall flake rate of test)\n",
    "\n",
    "In order to provide maxium flexibility for the end-user of this work, instead of creating a number of dataframes to answer each of these specifc questions, we will define a long and narrow data structure (a list of tuples saved as a csv for now) that contains only 5 columns (\"timestamp\", \"tab\",\"grid\",\"test\",\"flake\"). This allows superset (or pandas) to perform the last filter and/or aggreagtion of interest to an end user. Which is to say, there may appear to be a lot of repetion within the final dataset, but each row should be unique, and it should provide the simpelest useability for an end-user.    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T21:18:51.978625Z",
     "start_time": "2021-02-09T21:18:51.454578Z"
    }
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "sys.path.append(\"../../..\")\n",
    "\n",
    "module_path_1 = os.path.abspath(os.path.join(\"../../../data-sources/TestGrid\"))\n",
    "if module_path_1 not in sys.path:\n",
    "    sys.path.append(module_path_1)\n",
    "\n",
    "from ipynb.fs.defs.testgrid_EDA import decode_run_length  # noqa: E402"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T21:18:56.350078Z",
     "start_time": "2021-02-09T21:18:51.981071Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load test file\n",
    "with gzip.open(\"../../../../data/raw/testgrid_810.json.gz\", \"rb\") as read_file:\n",
    "    testgrid_data = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T21:18:56.365547Z",
     "start_time": "2021-02-09T21:18:56.352827Z"
    }
   },
   "outputs": [],
   "source": [
    "def testgrid_labelwise_encoding(data, label):\n",
    "\n",
    "    \"\"\"\n",
    "    Run length encode the dataset and unroll the dataset into a list.\n",
    "    Return flattened list after encoding specified value as\n",
    "    True and rest as False\n",
    "    \"\"\"\n",
    "\n",
    "    percent_label_by_grid_csv = []\n",
    "\n",
    "    for tab in data.keys():\n",
    "\n",
    "        for grid in data[tab].keys():\n",
    "            current_grid = data[tab][grid]\n",
    "            if len(current_grid[\"grid\"]) == 0:\n",
    "                pass\n",
    "            else:\n",
    "                # get all timestamps for this grid (x-axis of grid)\n",
    "                timestamps = [\n",
    "                    datetime.datetime.fromtimestamp(x // 1000)\n",
    "                    for x in current_grid[\"timestamps\"]\n",
    "                ]\n",
    "                # get all test names for this grid (y-axis of grid)\n",
    "                tests = [\n",
    "                    current_grid[\"grid\"][i][\"name\"]\n",
    "                    for i in range(len(current_grid[\"grid\"]))\n",
    "                ]\n",
    "                # unroll the run-length encoding and set bool for flake or not (x==13)\n",
    "                decoded = [\n",
    "                    (\n",
    "                        np.array(\n",
    "                            decode_run_length(\n",
    "                                current_grid[\"grid\"][i][\"statuses\"]\n",
    "                            )\n",
    "                        )\n",
    "                        == label\n",
    "                    ).tolist()\n",
    "                    for i in range(len(current_grid[\"grid\"]))\n",
    "                ]\n",
    "                # add the timestamp to bool value\n",
    "                decoded = [list(zip(timestamps, g)) for g in decoded]\n",
    "                # add the test, tab and grid name to each entry\n",
    "                # TODO: any ideas for avoiding this quad-loop\n",
    "                for i, d in enumerate(decoded):\n",
    "                    for j, k in enumerate(d):\n",
    "                        decoded[i][j] = (k[0], tab, grid, tests[i], k[1])\n",
    "                # accumulate the results\n",
    "                percent_label_by_grid_csv.append(decoded)\n",
    "\n",
    "    # output above leaves us with a doubly nested list. Flatten\n",
    "    flat_list = [\n",
    "        item for sublist in percent_label_by_grid_csv for item in sublist\n",
    "    ]\n",
    "    flatter_list = [item for sublist in flat_list for item in sublist]\n",
    "\n",
    "    return flatter_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T21:19:14.516215Z",
     "start_time": "2021-02-09T21:18:56.367489Z"
    }
   },
   "outputs": [],
   "source": [
    "unrolled_list = testgrid_labelwise_encoding(testgrid_data, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T21:19:14.523760Z",
     "start_time": "2021-02-09T21:19:14.518905Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(datetime.datetime(2020, 10, 8, 20, 48, 5),\n",
       " '\"redhat-openshift-informing\"',\n",
       " 'release-openshift-okd-installer-e2e-aws-upgrade',\n",
       " 'Application behind service load balancer with PDB is not disrupted',\n",
       " False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unrolled_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T21:19:14.572932Z",
     "start_time": "2021-02-09T21:19:14.525319Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19483548"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unrolled_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T21:19:22.561708Z",
     "start_time": "2021-02-09T21:19:14.574520Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>tab</th>\n",
       "      <th>grid</th>\n",
       "      <th>test</th>\n",
       "      <th>flake</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-10-08 20:48:05</td>\n",
       "      <td>\"redhat-openshift-informing\"</td>\n",
       "      <td>release-openshift-okd-installer-e2e-aws-upgrade</td>\n",
       "      <td>Application behind service load balancer with ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-10-08 19:12:01</td>\n",
       "      <td>\"redhat-openshift-informing\"</td>\n",
       "      <td>release-openshift-okd-installer-e2e-aws-upgrade</td>\n",
       "      <td>Application behind service load balancer with ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-10-08 14:18:13</td>\n",
       "      <td>\"redhat-openshift-informing\"</td>\n",
       "      <td>release-openshift-okd-installer-e2e-aws-upgrade</td>\n",
       "      <td>Application behind service load balancer with ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-10-08 11:15:28</td>\n",
       "      <td>\"redhat-openshift-informing\"</td>\n",
       "      <td>release-openshift-okd-installer-e2e-aws-upgrade</td>\n",
       "      <td>Application behind service load balancer with ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-10-08 08:27:53</td>\n",
       "      <td>\"redhat-openshift-informing\"</td>\n",
       "      <td>release-openshift-okd-installer-e2e-aws-upgrade</td>\n",
       "      <td>Application behind service load balancer with ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp                           tab  \\\n",
       "0 2020-10-08 20:48:05  \"redhat-openshift-informing\"   \n",
       "1 2020-10-08 19:12:01  \"redhat-openshift-informing\"   \n",
       "2 2020-10-08 14:18:13  \"redhat-openshift-informing\"   \n",
       "3 2020-10-08 11:15:28  \"redhat-openshift-informing\"   \n",
       "4 2020-10-08 08:27:53  \"redhat-openshift-informing\"   \n",
       "\n",
       "                                              grid  \\\n",
       "0  release-openshift-okd-installer-e2e-aws-upgrade   \n",
       "1  release-openshift-okd-installer-e2e-aws-upgrade   \n",
       "2  release-openshift-okd-installer-e2e-aws-upgrade   \n",
       "3  release-openshift-okd-installer-e2e-aws-upgrade   \n",
       "4  release-openshift-okd-installer-e2e-aws-upgrade   \n",
       "\n",
       "                                                test  flake  \n",
       "0  Application behind service load balancer with ...  False  \n",
       "1  Application behind service load balancer with ...  False  \n",
       "2  Application behind service load balancer with ...  False  \n",
       "3  Application behind service load balancer with ...  False  \n",
       "4  Application behind service load balancer with ...  False  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to dataframe\n",
    "df_csv = pd.DataFrame(\n",
    "    unrolled_list, columns=[\"timestamp\", \"tab\", \"grid\", \"test\", \"flake\"]\n",
    ")\n",
    "df_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T21:19:31.520216Z",
     "start_time": "2021-02-09T21:19:22.564599Z"
    }
   },
   "outputs": [],
   "source": [
    "# saving only the first 1 million out of 30 million rows due to pvc limits. Expected data size is 7.5 GB\n",
    "# 250mb = 1 million --> 7500 mb = 30 million\n",
    "file = \"flakes.csv\"\n",
    "folder = \"../../../../data/processed/metrics/percent_flake_by_test\"\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "\n",
    "fullpath = os.path.join(folder, file)\n",
    "df_csv.head(1000000).to_csv(fullpath, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T21:19:31.524437Z",
     "start_time": "2021-02-09T21:19:31.522190Z"
    }
   },
   "outputs": [],
   "source": [
    "# Send to Ceph - TODO!\n",
    "# currently waiting on ceph bucket but it will look something like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-09T21:19:31.548034Z",
     "start_time": "2021-02-09T21:19:31.526038Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003037"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Overall flake percentage\n",
    "df_csv.head(1000000).flake.sum() / df_csv.head(1000000).flake.count()"
   ]
  }
 ],
 "metadata": {
  "finalized": {
   "timestamp": 1612822647050,
   "trusted": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
